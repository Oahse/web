# Dockerfile for the general Celery worker for processing standard background tasks.
# This image is optimized to include only the necessary code and dependencies,
# reducing its size and attack surface.

# Use Alpine Python for smaller image size, ideal for Docker environments.
FROM python:3.11-alpine

# Set working directory inside the container. All subsequent commands will run from here.
WORKDIR /app

# Install system dependencies required for building Python packages (e.g., psycopg2-binary, cryptography)
# and for other utilities.
RUN apk add --no-cache \
    gcc \
    musl-dev \
    postgresql-dev \
    libffi-dev \
    openssl-dev \
    cargo \
    rust

# Copy Python dependency requirements file. This is copied early to leverage Docker cache.
COPY requirements.txt .

# Install Python dependencies. Uses --no-cache-dir to keep the image slim.
RUN pip install --no-cache-dir -r requirements.txt

# Install additional Celery and Redis-related packages specifically needed for worker functionality.
RUN pip install --no-cache-dir \
    celery[redis]==5.3.4 \
    flower==2.0.1 \
    redis==4.6.0

# Selective Copy of application code needed for the general Celery worker.
# This avoids copying unnecessary files like API routes or frontend code.

# Copy core configuration, essential for settings (like REDIS_URL, database credentials).
COPY core/config.py core/
# Copy the base Celery app definition.
COPY celery_app.py .
# Copy all task modules for general purpose tasks (emails, notifications, orders).
COPY tasks/ tasks/
# Copy models and core database setup (for ORM access in tasks that interact with DB).
COPY models/ models/
COPY core/database.py core/
# Copy services that might be used by tasks (e.g., notification service, email service).
COPY services/ services/
# Ensure __init__.py files are present for Python's module system to work correctly.
COPY __init__.py .
COPY tasks/__init__.py tasks/
COPY services/__init__.py services/
COPY models/__init__.py models/


# Set Python path
ENV PYTHONPATH=/app

# Default command to run the general Celery worker.
# This command is typically overridden in docker-compose.yml to specify which queues to consume.
CMD ["celery", "-A", "celery_app", "worker", "--loglevel=info"]